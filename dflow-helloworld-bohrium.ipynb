{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee84207",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Installation](#Installation)\n",
    "- [Setup](#Setup)\n",
    "- [Run.py](#Run-py)\n",
    "- [Argo UI](#Argo-UI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc1df5",
   "metadata": {},
   "source": [
    "# <a name=\"Installation\"></a> Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf278315",
   "metadata": {},
   "source": [
    "## Prerequisite \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6466a",
   "metadata": {},
   "source": [
    "**(Skip this step if already installed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdceef6",
   "metadata": {},
   "source": [
    "Before using [dflow](#https://github.com/deepmodeling/dflow), we need to install the following two things:\n",
    "- Docker (Official installation instruction: https://docs.docker.com/desktop/mac/install/)\n",
    "- Minikube (Official installation instruction: https://minikube.sigs.k8s.io/docs/start/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737fb0f",
   "metadata": {},
   "source": [
    "## Install pydflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81781614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydflow in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (1.1.3)\n",
      "Requirement already satisfied: minio in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (7.1.9)\n",
      "Requirement already satisfied: kubernetes in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (24.2.0)\n",
      "Requirement already satisfied: urllib3 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (1.26.9)\n",
      "Requirement already satisfied: pyyaml in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (6.0)\n",
      "Requirement already satisfied: certifi in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (2022.6.15)\n",
      "Requirement already satisfied: jsonpickle in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (2.2.0)\n",
      "Requirement already satisfied: six in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (1.16.0)\n",
      "Requirement already satisfied: typeguard in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (2.13.3)\n",
      "Requirement already satisfied: argo-workflows==5.0.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pydflow) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from kubernetes->pydflow) (61.2.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from kubernetes->pydflow) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from kubernetes->pydflow) (0.58.0)\n",
      "Requirement already satisfied: requests in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from kubernetes->pydflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from kubernetes->pydflow) (2.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes->pydflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes->pydflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes->pydflow) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes->pydflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from requests->kubernetes->pydflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from requests->kubernetes->pydflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user_one/.conda/envs/hello-world/lib/python3.9/site-packages (from requests-oauthlib->kubernetes->pydflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584e93b",
   "metadata": {},
   "source": [
    "**Once installed, restart the jupyter notebook kernel to make the installation to take effect.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514080e",
   "metadata": {},
   "source": [
    "# <a name=\"Setup\"></a> Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9165f",
   "metadata": {},
   "source": [
    "## Minikube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fad61c",
   "metadata": {},
   "source": [
    "Dflow runs on kubernetes (k8s), so we need to start minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8199201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÑ  minikube v1.26.0 on Ubuntu 20.04 (amd64)\n",
      "‚ú®  Using the docker driver based on existing profile\n",
      "üëç  Starting control plane node minikube in cluster minikube\n",
      "üöú  Pulling base image ...\n",
      "üèÉ  Updating the running docker \"minikube\" container ...\n",
      "‚ùó  This container is having trouble accessing https://k8s.gcr.io\n",
      "üí°  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/\n",
      "üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...\u001b[K\u001b[K\n",
      "    ‚ñ™ kubelet.cgroup-driver=systemd\n",
      "üîé  Verifying Kubernetes components...\n",
      "    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "üåü  Enabled addons: storage-provisioner, default-storageclass\n",
      "üí°  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'\n",
      "üèÑ  Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\n"
     ]
    }
   ],
   "source": [
    "!minikube start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b3278",
   "metadata": {},
   "source": [
    "## Argo-workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96608ed1",
   "metadata": {},
   "source": [
    "Dflow is built on [argo-workflow](https://github.com/argoproj/argo-workflows), so we need to setup argo engine in k8s:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ce6db",
   "metadata": {},
   "source": [
    "1. To get started quickly, we can use the quick start manifest which will install Argo Workflows as well as some commonly used components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee482ee3-4a86-4982-b71e-93810fa1bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!alias kubectl=\"minikube kubectl --\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17768746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"argo\" already exists\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterworkflowtemplates.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/cronworkflows.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/workfloweventbindings.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtaskresults.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtasksets.argoproj.io unchanged\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtemplates.argoproj.io unchanged\n",
      "serviceaccount/argo unchanged\n",
      "serviceaccount/argo-server unchanged\n",
      "serviceaccount/github.com unchanged\n",
      "role.rbac.authorization.k8s.io/agent unchanged\n",
      "role.rbac.authorization.k8s.io/argo-role unchanged\n",
      "role.rbac.authorization.k8s.io/argo-server-role unchanged\n",
      "role.rbac.authorization.k8s.io/executor unchanged\n",
      "role.rbac.authorization.k8s.io/pod-manager unchanged\n",
      "role.rbac.authorization.k8s.io/submit-workflow-template unchanged\n",
      "role.rbac.authorization.k8s.io/workflow-manager unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/argo-clusterworkflowtemplate-role unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/argo-server-clusterworkflowtemplate-role unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/agent-default unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/argo-binding unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/argo-server-binding unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/executor-default unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/github.com unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/pod-manager-default unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/workflow-manager-default unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/argo-clusterworkflowtemplate-role-binding unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/argo-server-clusterworkflowtemplate-role-binding unchanged\n",
      "configmap/artifact-repositories unchanged\n",
      "configmap/workflow-controller-configmap unchanged\n",
      "secret/argo-postgres-config configured\n",
      "secret/argo-server-sso configured\n",
      "secret/argo-workflows-webhook-clients configured\n",
      "secret/my-minio-cred configured\n",
      "service/argo-server unchanged\n",
      "service/minio unchanged\n",
      "service/postgres unchanged\n",
      "service/workflow-controller-metrics unchanged\n",
      "priorityclass.scheduling.k8s.io/workflow-controller unchanged\n",
      "deployment.apps/argo-server configured\n",
      "deployment.apps/minio unchanged\n",
      "deployment.apps/postgres unchanged\n",
      "deployment.apps/workflow-controller unchanged\n"
     ]
    }
   ],
   "source": [
    "!minikube kubectl -- create ns argo\n",
    "!minikube kubectl -- apply --namespace argo -f argo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abfb16",
   "metadata": {},
   "source": [
    "2. To monitor the setup progress, we can look at the pod status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1339246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                   READY   STATUS    RESTARTS        AGE\n",
      "argo-server-7f779db785-lfxbv           1/1     Running   6 (4m53s ago)   158m\n",
      "minio-64889fc698-kzmjd                 1/1     Running   2 (5m49s ago)   158m\n",
      "postgres-6b5944c545-cdw7z              1/1     Running   3 (5m29s ago)   158m\n",
      "workflow-controller-74f9c77d7d-gffkl   1/1     Running   5 (4m50s ago)   158m\n"
     ]
    }
   ],
   "source": [
    "!minikube kubectl -- get pod -n argo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b953c4",
   "metadata": {},
   "source": [
    "**NOTE!!!!**: This process might take a while, depending on the internet speed. Wait and keep refreshing the above cell. Once the `STATUS` of all pods is `RUNNING`, you can proceed with the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd59f15",
   "metadata": {},
   "source": [
    "**IMPORTANT!!!!**\n",
    "\n",
    "3. Open a port-forward so you can access the UI:\n",
    "\n",
    "    Since we need to keep this UI running, we can run this command in the terminal:\n",
    "    \n",
    "```shell\n",
    "minikube kubectl -- --namespace argo port-forward deployment/argo-server 60001:2746 --address 0.0.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3089f5",
   "metadata": {},
   "source": [
    "We can access the Argo UI: https://your-bohrium-ip-address:60001\n",
    "\n",
    "Security warning will be shown but we can safely ignore it. This is because we haven't add ceritificate to this address. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ba0f6",
   "metadata": {},
   "source": [
    "# <a name=\"Run-py\"></a> Run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98d9ca",
   "metadata": {},
   "source": [
    "In the previous steps, we finished installing and seting up the necessary tools and environments for dflow to run. In this section, we will prepare a simple python script using dflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ad065",
   "metadata": {},
   "source": [
    "Imagine, we want to achieve the following workflow:\n",
    "\n",
    "Step 1. \n",
    "1. Echo a string to msg.txt \n",
    "    \n",
    "2. Echo a number and redirect it to results.txt \n",
    "    \n",
    "Step 2.\n",
    "1. Duplicate the content in msg.txt two times and redirect it to a new file\n",
    "    \n",
    "2. Get the value in results.txt and times the number by 2 and redirect it to results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbde00c",
   "metadata": {},
   "source": [
    "To construct a workflow in dflow, three parts are needed:\n",
    "1. Construct OP templates\n",
    "2. Instantiate the OP template to Step\n",
    "3. Put steps together and submit the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8409e",
   "metadata": {},
   "source": [
    "## Construct OP template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13ee1a",
   "metadata": {},
   "source": [
    "As explained in the [readme](https://github.com/dptech-corp/dflow#122--op-template), OP template is the fundamental component in dflow. For this particular workflow above, we need two OP templates:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d34e4",
   "metadata": {},
   "source": [
    "For step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4691c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow import ShellOPTemplate\n",
    "step1_templ = ShellOPTemplate(\n",
    "                name=\"Hello\",\n",
    "                image=\"alpine:latest\",\n",
    "                script=\"echo {{inputs.parameters.msg}} > /tmp/msg.txt && echo {{inputs.parameters.number}} > /tmp/results.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c88c1f",
   "metadata": {},
   "source": [
    "This defines the operation to be executed. Next, we need to setup the inputs and outputs for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd766ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow import InputParameter, OutputParameter, OutputArtifact\n",
    "step1_templ.inputs.parameters = {\n",
    "                            \"msg\": InputParameter(),\n",
    "                            \"number\": InputParameter(),\n",
    "}\n",
    "step1_templ.outputs.parameters = {\n",
    "                            \"out_param\": OutputParameter(value_from_path=\"/tmp/results.txt\")\n",
    "}\n",
    "step1_templ.outputs.artifacts = {\n",
    "                            \"out_art\": OutputArtifact(path=\"/tmp/msg.txt\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722a986",
   "metadata": {},
   "source": [
    "For step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7314a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_templ = ShellOPTemplate(\n",
    "                name=\"Duplicate\",\n",
    "                image=\"alpine:latest\",\n",
    "                script=\"cat /tmp/foo.txt /tmp/foo.txt > /tmp/bar.txt && echo $(({{inputs.parameters.number}}*2)) > /tmp/results.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74140453",
   "metadata": {},
   "source": [
    "This defines the operation to be executed. Notice 2 things:\n",
    "1. We duplicated the content in `/tmp/foo.txt` 2 times, instead of `/tmp/msg.txt` in step 1. This is because OPTemplates are indepednent of each other. To make `/tmp/foo.txt` the same as `/tmp/msg.txt`, we only need to initialize it correctly when instantiating the OP template.\n",
    "2. We redirected the output of the arithmetic operation to `/tmp/results.txt`. This is not the file appeared in step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dba8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow import InputArtifact\n",
    "step2_templ.inputs.artifacts = {\n",
    "                            \"in_art\":InputArtifact(path=\"/tmp/foo.txt\") \n",
    "}\n",
    "step2_templ.inputs.parameters = {\n",
    "                            \"number\": InputParameter(),\n",
    "}\n",
    "step2_templ.outputs.artifacts = {\n",
    "                            \"out_art\": OutputArtifact(path=\"/tmp/bar.txt\")\n",
    "}\n",
    "step2_templ.outputs.parameters = {\n",
    "                            \"out_param\": OutputParameter(value_from_path=\"/tmp/results.txt\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396f8ed",
   "metadata": {},
   "source": [
    "## Instantiate the OP template to Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ad3b2",
   "metadata": {},
   "source": [
    "`Step` in the central block for building a workflow. A `Step` is created by instantiating an OP template. When a `Step` is initialized, values of all input parameters and sources of all input artifacts declared in the OP template must be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd9bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow import Step\n",
    "\n",
    "step1 = Step (\n",
    "            name=\"step1\",\n",
    "            template=step1_templ,\n",
    "            parameters={\"msg\":\"HelloWorld!\", \"number\": 1},\n",
    ")\n",
    "step2 = Step(\n",
    "            name=\"step2\",\n",
    "            template=step2_templ,\n",
    "            parameters={\"number\":step1.outputs.parameters[\"out_param\"]},\n",
    "            artifacts={\"in_art\":step1.outputs.artifacts[\"out_art\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8aa19",
   "metadata": {},
   "source": [
    "Step 1 takes in two values as parameters: \"HelloWorld!\" and 1. Step 2 takes the values and files from step 1 as the input parameters and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf432e",
   "metadata": {},
   "source": [
    "## Put steps together and submit a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2c217",
   "metadata": {},
   "source": [
    "We finished building blocks of this workflow. Now we can put them togther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5510220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow.workflow import config\n",
    "config['host']=\"https://your-bohrium-ip-address:60001\"\n",
    "\n",
    "from dflow import Workflow\n",
    "wf = Workflow(name=\"helloworld\")\n",
    "wf.add(step1)\n",
    "wf.add(step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2aa4bf",
   "metadata": {},
   "source": [
    "This creates a workflow with name \"helloworld\" and adds two steps in series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cb0f4",
   "metadata": {},
   "source": [
    "We can then submit the workflow. One caveat: we will get warning about certificiate verification since we haven't yet added cerificate to the address we specified for the UI. To suppress it, we can run the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0e0b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fea0ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow has been submitted (ID: helloworld-5wgxn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'helloworld-5wgxn', 'generateName': 'helloworld-', 'namespace': 'argo', 'uid': '395b9225-39e3-489d-b17e-5755d3851113', 'resourceVersion': '14460', 'generation': 1, 'creationTimestamp': '2022-06-28T08:32:32Z', 'labels': {'workflows.argoproj.io/creator': 'system-serviceaccount-argo-argo-server'}, 'managedFields': [{'manager': 'argo', 'operation': 'Update', 'apiVersion': 'argoproj.io/v1alpha1', 'time': '2022-06-28T08:32:32Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:generateName': {}, 'f:labels': {'.': {}, 'f:workflows.argoproj.io/creator': {}}}, 'f:spec': {}, 'f:status': {}}}]}, 'spec': {'templates': [{'name': 'helloworld-steps', 'inputs': {}, 'outputs': {}, 'metadata': {}, 'steps': [[{'name': 'step1', 'template': 'hello', 'arguments': {'parameters': [{'name': 'msg', 'value': 'HelloWorld!'}, {'name': 'number', 'value': '1'}]}, 'continueOn': {}}], [{'name': 'step2', 'template': 'duplicate', 'arguments': {'parameters': [{'name': 'number', 'value': \"{{=steps['step1'].outputs.parameters['out_param']}}\"}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/foo.txt', 'from': '{{steps.step1.outputs.artifacts.out_art}}'}]}, 'continueOn': {}}]]}, {'name': 'hello', 'inputs': {'parameters': [{'name': 'msg'}, {'name': 'number'}]}, 'outputs': {'parameters': [{'name': 'out_param', 'valueFrom': {'path': '/tmp/results.txt'}}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/msg.txt'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'alpine:latest', 'command': ['sh'], 'resources': {}, 'source': 'echo {{inputs.parameters.msg}} > /tmp/msg.txt && echo {{inputs.parameters.number}} > /tmp/results.txt'}}, {'name': 'duplicate', 'inputs': {'parameters': [{'name': 'number'}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/foo.txt'}]}, 'outputs': {'parameters': [{'name': 'out_param', 'valueFrom': {'path': '/tmp/results.txt'}}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/bar.txt'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'alpine:latest', 'command': ['sh'], 'resources': {}, 'source': 'cat /tmp/foo.txt /tmp/foo.txt > /tmp/bar.txt && echo $(({{inputs.parameters.number}}*2)) > /tmp/results.txt'}}], 'entrypoint': 'helloworld-steps', 'arguments': {}, 'serviceAccountName': 'argo'}, 'status': {'startedAt': None, 'finishedAt': None}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39411f8a",
   "metadata": {},
   "source": [
    "Another caveat: if you want to rerun the workflow, you need to start a new workflow by reruning `wf = Workflow(name=\"helloworld\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb86911",
   "metadata": {},
   "source": [
    "# <a name=\"Argo-UI\"></a> Argo UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892ecb3",
   "metadata": {},
   "source": [
    "After finishing the previous steps, we can access the workflow we just ran on the UI (https://127.0.0.1:2746)\n",
    "\n",
    "We should see the following once loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5f720",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/argoui_main_page.png\" alt=\"argoUI_mainpage\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7e833",
   "metadata": {},
   "source": [
    "We can see the workflow we just ran. Left click it then we can see the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21750c04",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/workflow_overview.png\" alt=\"workflow_overview\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab46bd",
   "metadata": {},
   "source": [
    "This gives us an overview of the workflow. The first node does not do anything. The two following nodes are the steps specified by us. Click on it then we can see more information about each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc1374",
   "metadata": {},
   "source": [
    "We can access the input/outputs of step 2. We can see the parameters of the step on the UI. We can download `out_art` by clicking the download buttom. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73952d83",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/access_one_node.png\" alt=\"access_one_node\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69662a54",
   "metadata": {},
   "source": [
    "After decompressing it, you should see a file named `bar.txt`. (This is also what we specified). Open it, you should see `HelloWorld!\\nHelloWorld!`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
